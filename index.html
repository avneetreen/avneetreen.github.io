<!DOCTYPE html>
<html lang="en">

<head>
    <title>Avneet Kaur</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="style.css">
    
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  <h1>Avneet Kaur </h1> 
                  <div style="font-family: 'JetBrains Mono',monospace;">
                    avneetreen[dot]github[dot]io</div>
                   <br>
                </p>
    
                <p><div style="font-family: 'JetBrains Mono',monospace;"> 
                  Hi, I'm Avneet. Based in Copenhagen, I'm a cloud engineer at Novo Nordisk <a target="_blank" href="https://fonts.google.com/specimen/Roboto+Mono"> Novo Nordisk</a>, where I work on scalable infrastructure solutions enabling research in healthcare . I hold a Master's degree in Computer Science from the University of Copenhagen, specializing in Machine Learning and Data Sciences. My research and professional interests focus in Applied AI/ Natural Language Processing, AI Safety, developing robust frameworks for secure AI deployment, exploring LLM architectures and responsible deployment, and building intelligent language systems with emphasis on safety and alignment. </div> </p> 
                    
                <p style="text-align:left">
                  <a href="mailto:avneet14027@iiitd.ac.in">Email</a> &nbsp;&#8226;&nbsp;
                  <a href="data/avneet_kaur_cv.pdf">CV</a> &nbsp;&#8226;&nbsp;
                  <a href="https://www.linkedin.com/in/avneetkaur97/">Linkedin</a> &nbsp;&#8226;&nbsp;
                  <a href="https://scholar.google.com/citations?user=Qoun_HcAAAAJ&hl=en">Google Scholar</a> &nbsp;&#8226;&nbsp;
                  <a href="https://github.com/avneetreen">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/image_profile.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/image_profile.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          

    

   
    <section class="papertile" title = "Research Work"> 
      <p  class="sectiontitle"> Publications </p>
      <p class="first">   
      <a target="_blank" rel="noopener noreferrer" href="https://ojs.aaai.org/index.php/AAAI/article/view/7191"> Multidimensional Analysis of Trust in News Articles </a><br>
      <u>Kaur, A.</u>, Leekha M., Chawla U., Agarwal A., Saxena M., Madaan Ni., Kannan K., Mehta S.(2019). <i>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2020)</i>
      </p> 
      <p class="second">   
      <a target="_blank" rel="noopener noreferrer" href="https://link.springer.com/chapter/10.1007/978-3-030-00671-6_15"> That's interesting, tell me more! finding descriptive support passages for knowledge graph relationships </a><br>
      Bhatia S., Dwivedi P., <u>Kaur, A.</u> <i>Proceedings of the AAAI Conference on Artificial Intelligence (ISWC 2018)</i>
      </p> 
            <a target="_blank" rel="noopener noreferrer" href="https://academic.oup.com/nar/article/46/D1/D1210/4559748"> FlavorDB: a database of flavor molecules </a><br>
      Garg N., Sethupathy A., Tuwani R., Nk R., Dokania S., Iyer A., Gupta A., Agrawal S., Singh N., Shukla S., Kathuria K., Badhwar R., Kanji R., Jain A., <u>Kaur, A.</u>, Nagpal R., Bagler G. <i>Nucleic acids research (NAR 2018)</i>
    </section>
    
    
    <section class="papertile" title = "Research Projects"> 
    <p  class="sectiontitle"> Research Projects</p>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


      <tr>
        <td style="padding:0px;width:25%;vertical-align:middle">
          <div class="papertile">

            <img src='images/expedition_aya.png' width="180">
          </div>
        </td>
        <td style="padding:10px;width:75%;vertical-align:middle">
          <a href="">
            <span>The Language Effect</span>
          </a><br>
          <em><a href="https://sites.google.com/cohere.com/expedition-aya/project-showcase?authuser=0>"> Expedition AYA, Cohere Labs></a></em>, July 2024 <br> <br> 
          <p>
            In this project, we developed a multilingual framework to assess political biases in large language models (LLMs) across different languages, addressing limitations in understanding language-sensitive retrieval of political opinions. The approach involves data collection, model training, bias measurement, and the development of a multilingual framework. The anticipated outcomes include insights into language-sensitive opinion retrieval and the establishment of a foundation for more inclusive and language-aware LLMs.
            <br><a href="https://cohere.com/blog/empowering-others-to-explore-the-next-frontier-expedition-aya">Featured as the most innovative project in Cohere for AI Blog post</a> 
          
          <br>
            <a href="https://docs.google.com/presentation/d/1KkqwQBc6kbAPsIsIphN6YawC-eH-UEhm4umuOnPid7E/edit?slide=id.p#slide=id.p">Slides</a> <br> 
          </p>
        </td>
      </tr>

      <tr><td><p></p></td><td><p></p></td></tr>

      <tr>
        <td style="padding:0px;width:25%;vertical-align:middle">
          <div class="papertile">

            <img src='images/code_based.png' width="180">
          </div>
        </td>
        <td style="padding:10px;width:75%;vertical-align:middle">
          <a href="">
            <span>Code Based Synthetic Data Pipeline for Multimodal data</span>
          </a><br>
          <em><a href="https://sites.google.com/cohere.com/expedition-aya-2025/2025-expedition-projects?authuser=0"> Expedition AYA, Cohere Labs></a></em>, May 2025 <br> <br> 
          <p>
            In this project, we developed a Code Based Synthetic Data Pipeline for Multimodal data to train, enhance, and evaluate multimodal models such as Vision Language Models (VLMs).
            <br>
            <a href="https://github.com/avneetreen/Code-based-Synthetic-Multimodal-Data-Generation">Code</a>
            /
            <a href="https://docs.google.com/presentation/d/1VX-q1x-GgjFi-rwGNUZ4n2w0C49uxncVQsfN0FwJyAE/edit?slide=id.g35143b7bb69_0_0#slide=id.g35143b7bb69_0_0">Slides</a> <br> 
          </p>
        </td>
      </tr>

      <tr><td><p></p></td><td><p></p></td></tr>

      <tr>
        <td style="padding:0px;width:25%;vertical-align:middle">
          <div class="papertile">

            <img src='images/mlcc.png' width="180">
          </div>
        </td>
        <td style="padding:10px;width:75%;vertical-align:middle">
          <a href="">
            <span>Multilingual Climate Change chatbot </span>
          </a><br>
          <em><a href="https://sites.google.com/cohere.com/expedition-aya/project-showcase?authuser=0">Expedition AYA, Cohere Labs</a></em>, July 2024 <br> <br> 
          <p>
            In this project, I contributed to the development of Our Multilingual Climate Chatbot project that aims to make climate research and education accessible to all.
            <br>
            <a href="https://github.com/Climate-Resilient-Communities/Climate-LLM-App">Code</a>
            / 
            <a href="https://docs.google.com/presentation/d/1es84bqQAJzjXEt_Ap0aXnBJDLOqfMR0pr71hPKOp9LA/edit?slide=id.g2858bb4e575_0_0#slide=id.g2858bb4e575_0_0">Slides</a>
            / 
            <a href="https://cohere.com/blog/empowering-others-to-explore-the-next-frontier-expedition-aya">Featured as the winner project in Cohere for AI Blog post</a> 
          
          </p> 
        </td>
      </tr>

      <tr><td><p></p></td><td><p></p></td></tr>

      <tr>
        <td style="padding:0px;width:25%;vertical-align:middle">
          <div class="papertile">

            <img src='images/predictions.jpg' width="200">
          </div>
        </td>
      <td style="padding:10px;width:75%;vertical-align:middle">
        <a href="https://www.researchgate.net/publication/373680658_Field_Boundary_Delineation">
          <span>Field Boundary Delineation applied to Danish agriculture</span>
        </a>
        <br>
        <em> University of Copenhagen, Department of Computer Science, DHI</em>, January 2021 <br> <br> 
        Avneet Kaur, <em>in collaboration with, </em> 
        <a target="_blank" href="https://research.ku.dk/search/result/?pure=en%2Fpersons%2Fstefan-oehmcke(5251ee43-5d02-4c29-910f-134b39d3b98e)%2Fpublications.html&publicationYearsFrom=2023&publicationYearsTo=2023"> Stefan Oehmcke, </a> 
        <a target="_blank" href="https://www.linkedin.com/in/kenneth-grogan-5408244a/?originalSubdomain=dk">Kenneth Grogan</a>
        <br>
        <p>
        Danish parcel delineation is an important task that currently has to
be done manually. In this work, we automate this laborious and error-prone process. Based on real data from Danish agriculture, we applied deep learning methods to efficiently detect parcels from freely available satellite images. To that end, we created a complete
data pipeline, from data collection over to processing, then building and evaluating the model. 
<br>
      <a href="https://github.com/avneetreen/Delineating-Field-Boundaries">Code</a>
      /
      <a href="https://www.researchgate.net/publication/373680658_Field_Boundary_Delineation">PDF</a> 
      /
      <a href="data/field_boundary_delineation.pdf">Slides</a> <br> 
        </p>

    </td>
    </tr>

    <tr><td><p></p></td><td><p></p></td></tr>
    
      <tr>
        <td style="padding:0px;width:25%;vertical-align:middle">
          <div class="papertile">

            <img src='images/brain.png' width="180">
          </div>
        </td>
        
        <td style="padding:0px;width:75%;vertical-align:middle">
          <a href="https://www.researchgate.net/publication/373680192_Development_of_a_robust_and_reproducible_preprocessing_pipeline_for_Positron_Emission_Tomography_PET_data">
            <span>Development of a robust and reproducible preprocessing pipeline for Positron Emission Tomography (PET) data</span>
          </a><br>
          <em>M.Sc. Thesis, University of Copenhagen, Department of Computer Science</em>, January 2022 <br> <br> 
          Avneet Kaur, <em>under the supervision of, </em> 
          <a target="_blank" href="https://sites.google.com/view/melanieganz/home"> Melanie Ganz-Benjaminsen, </a> 
          <a target="_blank" href="https://mnoergaard.github.io/">Martin NÃ¸rgaard</a>, Vincent Beliveau 
          <br>
          <p>
          We developed an open, robust and automated preprocessing pipeline for PET data using existing state-of-the-art neuroimaging software and implemented using Nipype. 
          To test the pipeline for robustness and computational reproducibility, the pipeline was tested on three datasets from different scanners and tracers across different computational environments.
          <br>
          <a href="https://github.com/openneuropet/PET_pipelines/tree/main/pet_nipype">Code</a>
          /
          <a href="https://www.researchgate.net/publication/373680192_Development_of_a_robust_and_reproducible_preprocessing_pipeline_for_Positron_Emission_Tomography_PET_data">PDF</a> 
          / 
          <a href="data/msc_defence.pdf">Slides</a> 
        </p>

          <br> 
        </td>
      </tr>

      <tr><td><p></p></td><td><p></p></td></tr>

      
  
      </tbody>
      </table>


    </section>
    <section title = "Education"> 
    
    </section>
        </td>
     </tr>
    </tbody></table>

    <!--div class="footer" style="font-size: 12px; text-align: center;">design inspired from <a href="https://github.com/jonbarron/jonbarron_website">jon barron's website</a> </div-->
</body>

</html>
